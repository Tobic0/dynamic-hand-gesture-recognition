<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.4"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Dynamic hand gesture recognition system using RNN with LSTM: Dynamic hand gesture recognition using RNN with LSTM</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Dynamic hand gesture recognition system using RNN with LSTM
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.4 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Dynamic hand gesture recognition using RNN with LSTM </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p >This is the official documentation of the dynamic hand gesture recognition system based on Google's MediaPipe framework and Recurrent Neural Network with Long Short Term Memory project which can be seen at the following GitHub repo: <a href="https://github.com/Tobic0/dynamic-hand-gesture-recognition">https://github.com/Tobic0/dynamic-hand-gesture-recognition</a> <br  />
<br  />
 This documentation contains a brief overview of the main code pages used for executing the application:</p><ul>
<li><a class="el" href="namespacevideo__recorder.html" title="Documentation for video recorder application.">video_recorder</a></li>
<li><a class="el" href="namespacevideo__augmentation.html" title="Documentation for video augmentation application.">video_augmentation</a></li>
<li><a class="el" href="namespaceextract__from__video.html" title="Documentation for video landmark extraction.">extract_from_video</a></li>
<li><a class="el" href="namespacekeypoint__classification.html" title="Documentation for the RNN structure and training.">keypoint_classification</a></li>
<li>main <br  />
<br  />
 In particular the working flow is the following: first you need to record the hand gestures using the <a class="el" href="namespacevideo__recorder.html" title="Documentation for video recorder application.">video_recorder</a> where you can select which gesture to record or using external tools, it is important to record many videos as possible as, the more the better; afterwards using <a class="el" href="namespacevideo__augmentation.html" title="Documentation for video augmentation application.">video_augmentation</a> we increment the number of videos by augmenting the original one by changing randomly the brightness and by adding a random rotation. At this point all the input data is ready for running the <a class="el" href="namespaceextract__from__video.html" title="Documentation for video landmark extraction.">extract_from_video</a> script which uses MediaPipe hands solution for detecting and generating hand landmarks which are then stored in an appropriate folder after appropriate transformations are made by the <a class="el" href="namespacelandmarks__transformer.html" title="Documentation for the landmarks&#39; transformer   This script is used for transforming in an appropriate...">landmarks_transformer</a>. Afterwards we can train our recurrent neural network by running the <a class="el" href="namespacekeypoint__classification.html" title="Documentation for the RNN structure and training.">keypoint_classification</a> script which at the end will save the model together with the weights that been computed. At the end it is only necessary to run the main script for a real time application. Specifically the program uses the MediaPipe framework to detect hands and if it detects one then the landmarks are extracted and processed using the <a class="el" href="namespacelandmarks__transformer.html" title="Documentation for the landmarks&#39; transformer   This script is used for transforming in an appropriate...">landmarks_transformer</a>, and using the neural network previously trained it predicts which hand gesture was performed. </li>
</ul>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.4 </li>
  </ul>
</div>
</body>
</html>
